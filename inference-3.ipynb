{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"},"kaggle":{"accelerator":"gpu","dataSources":[{"sourceId":43873,"databundleVersionId":5585780,"sourceType":"competition"},{"sourceId":5796643,"sourceType":"datasetVersion","datasetId":3329376},{"sourceId":5797143,"sourceType":"datasetVersion","datasetId":3329627},{"sourceId":5797193,"sourceType":"datasetVersion","datasetId":3329654},{"sourceId":5811182,"sourceType":"datasetVersion","datasetId":3338243},{"sourceId":5836009,"sourceType":"datasetVersion","datasetId":3354780},{"sourceId":5836408,"sourceType":"datasetVersion","datasetId":3355046},{"sourceId":5840466,"sourceType":"datasetVersion","datasetId":3357629}],"dockerImageVersionId":30498,"isInternetEnabled":false,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# Using Donut Model for OCR.","metadata":{}},{"cell_type":"code","source":"import re\nfrom pathlib import Path\nfrom typing import List\nfrom functools import partial\n\nfrom transformers import (\n    DonutProcessor,\n    VisionEncoderDecoderConfig,\n    VisionEncoderDecoderModel,\n)\nimport torch\nfrom torch.utils.data import DataLoader\nimport numpy as np\nimport pandas as pd\nfrom datasets import Dataset\nfrom datasets import Image as ds_img\nfrom tqdm.auto import tqdm","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2023-06-05T04:55:22.704834Z","iopub.execute_input":"2023-06-05T04:55:22.705105Z","iopub.status.idle":"2023-06-05T04:55:35.733241Z","shell.execute_reply.started":"2023-06-05T04:55:22.70508Z","shell.execute_reply":"2023-06-05T04:55:35.732201Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"class CFG:\n    \n    test_grayscale = True\n    debug_clean = False\n    \n    batch_size = 4\n    image_path = \"/kaggle/input/benetech-making-graphs-accessible/test/images\"\n    max_length = 512\n    model_dir = \"/kaggle/input/donut-model\"\n\nBOS_TOKEN = \"<|BOS|>\"\nX_START = \"<x_start>\"\nX_END = \"<x_end>\"\nY_START = \"<y_start>\"\nY_END = \"<y_end>\"\n\nPLACEHOLDER_DATA_SERIES = \"0;0\"\nPLACEHOLDER_CHART_TYPE = \"line\"","metadata":{"execution":{"iopub.status.busy":"2023-06-05T04:55:35.735044Z","iopub.execute_input":"2023-06-05T04:55:35.737136Z","iopub.status.idle":"2023-06-05T04:55:35.743201Z","shell.execute_reply.started":"2023-06-05T04:55:35.737097Z","shell.execute_reply":"2023-06-05T04:55:35.742025Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def clean_preds(x: List[str], y: List[str]):\n    \"\"\"\n    This function cleans the x and y values predicted by Donut.\n\n    Because it is a generative model, it can insert any character in the \n    model's vocabulary into the prediction string. This function primarily removes\n    characters that prevent a number from being cast to a float.\n\n    Example:\n\n    x = [\"11\", \"12\", \"1E\", \"14\", \"15\"]\n    y = [\"Monday\", \"Tuesday\", \"Wednesday\", \"Thursday\", \"Friday\"]\n\n    # float(\"1E\") will throw an error\n\n    new_x, new_y = clean_preds(x, y)\n\n    new_x = [\"11\", \"12\", \"13\", \"14\", \"15\"]\n    new_y = [\"Monday\", \"Tuesday\", \"Wednesday\", \"Thursday\", \"Friday\"]\n\n    Args:\n        x (List[str]): The x values predicted by Donut.\n        y (List[str]): The y values predicted by Donut.\n\n    Returns:\n        x (List[str]): The cleaned x values.\n        y (List[str]): The cleaned y values.\n    \"\"\"\n    \n    def clean(str_list):\n        \n        new_list = []\n        for temp in str_list:\n            if \".\" not in temp:\n                dtype = int\n            else:\n                dtype = float\n            try:\n                # First try removing whitespace e.g. float(\"10 0\") will fail\n                temp = dtype(re.sub(\"\\s\", \"\", temp))\n            except ValueError:\n\n                # remove everything that isn't a digit, period, negative sign, or the letter e\n                # It could be \"1e-5\" or \"-0.134\"\n\n                #temp = re.sub(r\"[^0-9\\.\\-eE]\", \"\", temp)\n\n                if len(temp) == 0:\n                    temp = 0\n                else:\n                    multiple_periods = len(re.findall(r\"\\.\", temp)) > 1\n                    multiple_negative_signs = len(re.findall(r\"\\-\", temp)) > 1\n                    multiple_e = len(re.findall(r\"[eE]\", temp)) > 1\n\n                    # Put negative sign in from of it all\n                    if multiple_negative_signs:\n                        temp = \"-\" + re.sub(r\"\\-\", \"\", temp)\n\n                    # Keep first period if there are multiple\n                    if multiple_periods:\n                        chunks = temp.split(\".\")\n                        try:\n                            temp = chunks[0] + \".\" + \"\".join(chunks[1:])\n                        except IndexError:\n                            temp = \"\".join(chunks)\n                    \n                    # Keep last e in case it is \"e1e-5\"\n                    if multiple_e:\n                        while temp.lower().startswith(\"e\"):\n                            temp = temp[1:]\n                        \n                        while temp.lower().endswith(\"e\"):\n                            temp = temp[:-1]\n                            \n                        chunks = temp.split(\"e\")\n                        try:\n                            temp = chunks[0:-1] + \"e\" + \"\".join(chunks[-1])\n                        except IndexError:\n                            temp = \"\".join(chunks)\n                try:\n                    temp = dtype(temp)\n                except ValueError:\n                    temp = 0\n                    \n            new_list.append(temp)\n\n        return new_list\n\n    all_x_chars = \"\".join(x)\n    all_y_chars = \"\".join(y)\n\n    frac_num_x = len(re.sub(r\"[^\\d]\", \"\", all_x_chars)) / len(all_x_chars)\n    frac_num_y = len(re.sub(r\"[^\\d]\", \"\", all_y_chars)) / len(all_y_chars)\n    if CFG.debug_clean:\n        print(f\"x before clean (len={len(x)})\", x)\n        print(f\"y before clean (len={len(y)})\", y)\n\n    if frac_num_x >= 0.5:\n        x = clean(x)\n    else:\n        x = [s.strip() for s in x]\n    \n    \n    if frac_num_y >= 0.5:\n        y = clean(y)\n    else:\n        y = [s.strip() for s in y]\n        \n    if CFG.debug_clean:\n        print(f\"x after clean (len={len(x)})\", x)\n        print(f\"y after clean (len={len(x)})\", x)\n\n    return x, y\n    \n\ndef string2preds(pred_string: str):\n    \"\"\"\n    Conver the prediction string from Donut to a chart type and x and y values.\n\n    Checks to make sure the special tokens are present and that the x and y values are not empty.\n    Will truncate the list of values to the smaller length of the two lists. This is because the \n    lengths of the x and y values must be the same to earn any points.\n\n    Args:\n        pred_string (str): The prediction string from Donut.\n\n    Returns:\n        chart_type (str): The chart type predicted by Donut.\n        x (List[str]): The x values predicted by Donut.\n        y (List[str]): The y values predicted by Donut.\n    \"\"\"\n\n    if \"<dot>\" in pred_string:\n        chart_type = \"dot\"\n    elif \"<horizontal_bar>\" in pred_string:\n        chart_type = \"horizontal_bar\"\n    elif \"<vertical_bar>\" in pred_string:\n        chart_type = \"vertical_bar\"\n    elif \"<scatter>\" in pred_string:\n        chart_type = \"scatter\"\n    elif \"<line>\" in pred_string:\n        chart_type = \"line\"\n    else:\n        return \"vertical_bar\", [], []\n    \n    \n    if not all([x in pred_string for x in [X_START, X_END, Y_START, Y_END]]):\n        return chart_type, [], []\n    \n    pred_string = re.sub(r\"<one>\", \"1\", pred_string)\n\n    x = pred_string.split(X_START)[1].split(X_END)[0].split(\";\")\n    y = pred_string.split(Y_START)[1].split(Y_END)[0].split(\";\")\n\n    if len(x) == 0 or len(y) == 0:\n        return chart_type, [], []\n\n    #min_length = min(len(x), len(y))\n\n    ##x = x[:min_length]\n    ##y = y[:min_length]\n\n    #y = clear_out(y)\n    x, y = clean_preds(x, y)\n    \n    return chart_type, x, y","metadata":{"execution":{"iopub.status.busy":"2023-06-05T04:55:35.744967Z","iopub.execute_input":"2023-06-05T04:55:35.745695Z","iopub.status.idle":"2023-06-05T04:55:35.769388Z","shell.execute_reply.started":"2023-06-05T04:55:35.745664Z","shell.execute_reply":"2023-06-05T04:55:35.76842Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"image_dir = Path(CFG.image_path)\nimages = list(image_dir.glob(\"*.jpg\"))\n\nds = Dataset.from_dict(\n    {\"image_path\": [str(x) for x in images], \"id\": [x.stem for x in images]}\n).cast_column(\"image_path\", ds_img())\n\ndef preprocess(examples, processor):\n    pixel_values = []\n\n    for sample in examples[\"image_path\"]:\n        arr = np.array(sample)\n        \n        # There are some grayscale images that were making this fail\n        # This prevents that.\n        if len(arr.shape) == 2:\n            print(\"Changing grayscale to 3 channel format\")\n            print(arr.shape)\n            arr = np.stack([arr]*3, axis=-1)\n        \n        pixel_values.append(processor(arr, random_padding=True).pixel_values)\n        \n        \n    return {\n        \"pixel_values\": torch.tensor(np.vstack(pixel_values)),\n    }\n\n\nmodel = VisionEncoderDecoderModel.from_pretrained(CFG.model_dir)\nmodel.eval()\n\ndevice = torch.device(\"cuda:0\")\n\nmodel.to(device)\ndecoder_start_token_id = model.config.decoder_start_token_id\nprocessor = DonutProcessor.from_pretrained(CFG.model_dir)\n\nids = ds[\"id\"]\nds.set_transform(partial(preprocess, processor=processor))\n\ndata_loader = DataLoader(\n    ds, batch_size=CFG.batch_size, shuffle=False\n)\n\n\nall_generations = []\nfor batch in tqdm(data_loader):\n    pixel_values = batch[\"pixel_values\"].to(device)\n\n    batch_size = pixel_values.shape[0]\n\n    decoder_input_ids = torch.full(\n        (batch_size, 1),\n        decoder_start_token_id,\n        device=pixel_values.device,\n    )\n\n    try:\n        outputs = model.generate(\n            pixel_values,\n            decoder_input_ids=decoder_input_ids,\n            max_length=CFG.max_length,\n            early_stopping=True,\n            pad_token_id=processor.tokenizer.pad_token_id,\n            eos_token_id=processor.tokenizer.eos_token_id,\n            use_cache=True,\n            num_beams=1,\n            temperature=1,\n            top_k=1,\n            return_dict_in_generate=True,\n        )\n\n        all_generations.extend(processor.batch_decode(outputs.sequences))\n        \n    except:\n        all_generations.extend([\"\"]*batch_size)\n        \n\nchart_types, x_preds, y_preds = [], [], []\nfor gen in all_generations:\n    try:\n        chart_type, x, y = string2preds(gen)\n        new_chart_type = chart_type\n        x_str = \";\".join(list(map(str, x)))\n        y_str = \";\".join(list(map(str, y)))\n    except Exception as e:\n        print(\"Failed to convert to string:\", gen)\n        print(e)\n        new_chart_type = PLACEHOLDER_CHART_TYPE\n        x_str = PLACEHOLDER_DATA_SERIES\n        y_str = PLACEHOLDER_DATA_SERIES\n\n    if len(x_str) == 0:\n        x_str = PLACEHOLDER_DATA_SERIES\n    if len(y_str) == 0:\n        y_str = PLACEHOLDER_DATA_SERIES\n        \n    chart_types.append(new_chart_type)\n    x_preds.append(x_str)\n    y_preds.append(y_str)","metadata":{"execution":{"iopub.status.busy":"2023-06-05T04:55:35.772561Z","iopub.execute_input":"2023-06-05T04:55:35.7733Z","iopub.status.idle":"2023-06-05T04:56:06.140646Z","shell.execute_reply.started":"2023-06-05T04:55:35.77327Z","shell.execute_reply":"2023-06-05T04:56:06.139699Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df = pd.DataFrame(chart_types)\ndf.columns = ['chart_types']\nx = []\nfor i in range(len(x_preds)):\n    l = x_preds[i].split(';')\n    x.append(l)\ny = []\nfor i in range(len(y_preds)):\n    l = y_preds[i].split(';')\n    y.append(l)\ndf['image_id'] = ids\ndf['x_val'] = x\ndf['y_val'] = y","metadata":{"execution":{"iopub.status.busy":"2023-06-05T04:56:06.142103Z","iopub.execute_input":"2023-06-05T04:56:06.1427Z","iopub.status.idle":"2023-06-05T04:56:06.157417Z","shell.execute_reply.started":"2023-06-05T04:56:06.142665Z","shell.execute_reply":"2023-06-05T04:56:06.156022Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Axis points","metadata":{}},{"cell_type":"code","source":"import torch\nimport torch.nn as nn\nimport torch.optim as optim\nfrom torch.utils.data import Dataset, DataLoader\nimport torchvision.transforms as transforms\nimport torchvision.transforms.functional as TF\nimport torchvision.models as models\nimport numpy as np\nimport pandas as pd\nimport cv2\nfrom PIL import Image\nimport matplotlib.pyplot as plt","metadata":{"execution":{"iopub.status.busy":"2023-06-05T04:56:06.158962Z","iopub.execute_input":"2023-06-05T04:56:06.159324Z","iopub.status.idle":"2023-06-05T04:56:06.515381Z","shell.execute_reply.started":"2023-06-05T04:56:06.159292Z","shell.execute_reply":"2023-06-05T04:56:06.514447Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import torch\nimport torch.nn as nn\nfrom torchvision import models\nimport pytorch_lightning as pl\nfrom torch.nn.utils.rnn import pad_sequence\n\nclass CNN(pl.LightningModule):\n    def __init__(self, max_num_points):\n        super(CNN, self).__init__()\n        resnet = models.resnet18(weights=None)\n        self.resnet_layers = nn.Sequential(*list(resnet.children())[:-1])\n        self.fc1 = nn.Linear(512, 128)\n        self.fc2 = nn.Linear(128, max_num_points * 2)\n        self.fc3 = nn.Linear(128, max_num_points * 4)\n\n    def forward(self, x):\n        x = self.resnet_layers(x)\n        x = x.view(x.size(0), -1)\n        x = nn.functional.relu(self.fc1(x))\n        points = self.fc2(x)\n        labels = self.fc3(x)\n        points = points.view(points.size(0), -1, 2)\n        labels = labels.view(labels.size(0), -1, 4)\n        return {'points': points, 'labels': labels}\n\n    def training_step(self, batch, batch_idx):\n        images, targets = batch\n        outputs = self(images)\n        loss_points = self.compute_loss_points(outputs['points'], targets['points'], targets['mask'])\n        loss_labels = self.compute_loss_labels(outputs['labels'], targets['labels'])\n        loss = loss_points + loss_labels\n        self.log('train_loss', loss)\n        return loss\n\n    def validation_step(self, batch, batch_idx):\n        images, targets = batch\n        outputs = self(images)\n        loss_points = self.compute_loss_points(outputs['points'], targets['points'], targets['mask'])\n        loss_labels = self.compute_loss_labels(outputs['labels'], targets['labels'])\n        loss = loss_points + loss_labels\n        self.log('val_loss', loss)\n        return loss\n\n    def compute_loss_points(self, outputs, targets, mask):\n        criterion = nn.MSELoss(reduction='none')\n        loss = criterion(outputs, targets.float())\n        masked_loss = loss * mask.unsqueeze(-1).float()\n        mean_loss = torch.sum(masked_loss) / torch.sum(mask)\n        return mean_loss\n    \n    def compute_loss_labels(self, outputs, targets):\n        criterion = nn.CrossEntropyLoss(reduction='none')\n        batch_size, seq_length, num_classes = outputs.size()\n        reshaped_outputs = outputs.view(batch_size * seq_length, num_classes)\n        reshaped_targets = targets.view(batch_size * seq_length)\n        loss = criterion(reshaped_outputs, reshaped_targets)\n        mean_loss = torch.mean(loss)\n        return mean_loss\n\n    def configure_optimizers(self):\n        optimizer = torch.optim.Adam(model.parameters(), lr=0.001, weight_decay=0.001)\n        return optimizer","metadata":{"execution":{"iopub.status.busy":"2023-06-05T04:56:06.516853Z","iopub.execute_input":"2023-06-05T04:56:06.517443Z","iopub.status.idle":"2023-06-05T04:56:07.848615Z","shell.execute_reply.started":"2023-06-05T04:56:06.517388Z","shell.execute_reply":"2023-06-05T04:56:07.847687Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')","metadata":{"execution":{"iopub.status.busy":"2023-06-05T04:56:07.849907Z","iopub.execute_input":"2023-06-05T04:56:07.850252Z","iopub.status.idle":"2023-06-05T04:56:07.855664Z","shell.execute_reply.started":"2023-06-05T04:56:07.850221Z","shell.execute_reply":"2023-06-05T04:56:07.854632Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"model_x = CNN(max_num_points=25)\nmodel_x.load_state_dict(torch.load('/kaggle/input/x-axis-model-10/model (1).pth'))\nmodel_x.eval()\nmodel_x.to(device)\nmodel_y = CNN(max_num_points=25)\nmodel_y.load_state_dict(torch.load('/kaggle/input/y-axis-model-10/Y_Point_generation_weights_1.0.pth'))\nmodel_y.eval()\nmodel_y.to(device)","metadata":{"execution":{"iopub.status.busy":"2023-06-05T04:56:07.856971Z","iopub.execute_input":"2023-06-05T04:56:07.857782Z","iopub.status.idle":"2023-06-05T04:56:09.954248Z","shell.execute_reply.started":"2023-06-05T04:56:07.85775Z","shell.execute_reply":"2023-06-05T04:56:09.953342Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"ids = []\nimport os\ntest_dataset_dir = CFG.image_path\nfor filename in os.listdir(test_dataset_dir):\n    if filename.endswith(\".jpg\"):\n        ids.append(filename[:-4])\ntest_df = pd.DataFrame(ids)\ntest_df.columns = ['image_id']","metadata":{"execution":{"iopub.status.busy":"2023-06-05T04:56:09.958632Z","iopub.execute_input":"2023-06-05T04:56:09.959596Z","iopub.status.idle":"2023-06-05T04:56:09.966131Z","shell.execute_reply.started":"2023-06-05T04:56:09.959562Z","shell.execute_reply":"2023-06-05T04:56:09.965189Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from PIL import Image\nfrom torchvision import transforms\n\nclass CustDataset(Dataset):\n    def __init__(self, dataframe, image_dir, image_transform=None):\n        super().__init__()\n        self.image_ids = dataframe['image_id'].unique()\n        self.df = dataframe\n        self.image_dir = image_dir\n        self.image_transform = image_transform\n\n    def convert_to_rgb(self, image):\n        if image.mode != 'RGB':\n            image = image.convert('RGB')\n        return image\n\n    def __getitem__(self, index: int):\n        image_id = self.image_ids[index]\n        records = self.df[self.df['image_id'] == image_id]\n\n        image = Image.open(f'{self.image_dir}/{image_id}.jpg')\n        original_width, original_height = image.size\n\n        image = self.convert_to_rgb(image)\n\n        if self.image_transform is not None:\n            image = self.image_transform(image)\n\n        return image, image_id\n\n    def __len__(self) -> int:\n        return self.image_ids.shape[0]","metadata":{"execution":{"iopub.status.busy":"2023-06-05T04:56:09.967515Z","iopub.execute_input":"2023-06-05T04:56:09.968289Z","iopub.status.idle":"2023-06-05T04:56:09.978535Z","shell.execute_reply.started":"2023-06-05T04:56:09.968256Z","shell.execute_reply":"2023-06-05T04:56:09.977449Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from torchvision import transforms\n\nimage_transform = transforms.Compose([\n    transforms.Resize((256,256)),\n    transforms.ToTensor(),\n    transforms.Normalize(mean=[0.5, 0.5, 0.5], std=[0.5, 0.5, 0.5]),\n])","metadata":{"execution":{"iopub.status.busy":"2023-06-05T04:56:09.979882Z","iopub.execute_input":"2023-06-05T04:56:09.98043Z","iopub.status.idle":"2023-06-05T04:56:09.987985Z","shell.execute_reply.started":"2023-06-05T04:56:09.980378Z","shell.execute_reply":"2023-06-05T04:56:09.987024Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"DIR_INPUT = CFG.image_path\nDIR_TRAIN = f'{DIR_INPUT}'\ntest_dataset = CustDataset(test_df,DIR_TRAIN,image_transform=image_transform)","metadata":{"execution":{"iopub.status.busy":"2023-06-05T04:56:09.991318Z","iopub.execute_input":"2023-06-05T04:56:09.991615Z","iopub.status.idle":"2023-06-05T04:56:09.999216Z","shell.execute_reply.started":"2023-06-05T04:56:09.991585Z","shell.execute_reply":"2023-06-05T04:56:09.998338Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"test_data_loader = DataLoader(\n    test_dataset,\n    batch_size=32,\n    shuffle=False,\n    num_workers=2,\n)","metadata":{"execution":{"iopub.status.busy":"2023-06-05T04:56:10.000718Z","iopub.execute_input":"2023-06-05T04:56:10.001103Z","iopub.status.idle":"2023-06-05T04:56:10.009052Z","shell.execute_reply.started":"2023-06-05T04:56:10.001073Z","shell.execute_reply":"2023-06-05T04:56:10.008092Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"model_x.eval()\nmodel_y.eval()\nresults = []\nfor images,image_ids in test_data_loader:\n    images = images.to(device)\n    outputs_x = model_x(images)\n    outputs_y = model_y(images)\n    for i, image in enumerate(images):\n        points_x = outputs_x['points'][i].data.cpu().numpy()\n        labels_x = torch.argmax(outputs_x['labels'][i], dim=1).data.cpu().numpy()\n        points_x = points_x[labels_x == 1]\n        points_y = outputs_y['points'][i].data.cpu().numpy()\n        labels_y = torch.argmax(outputs_y['labels'][i], dim=1).data.cpu().numpy()\n        points_y = points_y[labels_y == 1]\n        image_id = image_ids[i]\n        result = {\n            'image_id': image_id,\n            'x_points': points_x,\n            'y_points': points_y,\n        }\n        results.append(result)\n    del images, outputs_x, outputs_y ","metadata":{"execution":{"iopub.status.busy":"2023-06-05T04:56:10.01056Z","iopub.execute_input":"2023-06-05T04:56:10.010966Z","iopub.status.idle":"2023-06-05T04:56:10.279065Z","shell.execute_reply.started":"2023-06-05T04:56:10.010937Z","shell.execute_reply":"2023-06-05T04:56:10.277334Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df2 = pd.DataFrame(results)","metadata":{"execution":{"iopub.status.busy":"2023-06-05T04:56:10.283262Z","iopub.execute_input":"2023-06-05T04:56:10.283587Z","iopub.status.idle":"2023-06-05T04:56:10.289908Z","shell.execute_reply.started":"2023-06-05T04:56:10.283556Z","shell.execute_reply":"2023-06-05T04:56:10.288701Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df2.head()","metadata":{"execution":{"iopub.status.busy":"2023-06-05T04:56:10.291374Z","iopub.execute_input":"2023-06-05T04:56:10.29201Z","iopub.status.idle":"2023-06-05T04:56:10.335571Z","shell.execute_reply.started":"2023-06-05T04:56:10.291953Z","shell.execute_reply":"2023-06-05T04:56:10.33456Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import matplotlib.pyplot as plt\ni = 2\nprint(df['x_val'][i])\nprint(df['y_val'][i])\npoints_x = df2['x_points'][i]\npoints_y = df2['y_points'][i]\nimg_path = CFG.image_path+'/'+df2['image_id'][i]+'.jpg'\nimage = cv2.imread(img_path)\nimg = cv2.resize(image, (256, 256))\nfig, ax = plt.subplots()\nax.imshow(img)\nfor point in points_x:\n    x = point[0]\n    y = point[1]\n    ax.plot(x, y, 'ro')\n\nfor point in points_y:\n    x = point[0]\n    y = point[1]\n    ax.plot(x, y, 'ro')\n\nax.axis('off')\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2023-06-05T04:56:10.336855Z","iopub.execute_input":"2023-06-05T04:56:10.337161Z","iopub.status.idle":"2023-06-05T04:56:10.49502Z","shell.execute_reply.started":"2023-06-05T04:56:10.337132Z","shell.execute_reply":"2023-06-05T04:56:10.494131Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def extend_y_axis(y_points,y_labels):\n    diff_points = y_points[1]-y_points[0]\n    diff_labels = y_labels[0]-y_labels[1]\n    data = [[y_points[0],y_labels[0]]]\n    for i in range(25):\n        point = data[i][0]+diff_points\n        labels = data[i][1]-diff_labels\n        data.append([point,labels])\n    return data","metadata":{"execution":{"iopub.status.busy":"2023-06-05T04:56:10.496425Z","iopub.execute_input":"2023-06-05T04:56:10.496996Z","iopub.status.idle":"2023-06-05T04:56:10.505731Z","shell.execute_reply.started":"2023-06-05T04:56:10.496964Z","shell.execute_reply":"2023-06-05T04:56:10.504482Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"extended_y = []\nfor i in range(len(df)):\n    points_y = df2['y_points'][i]\n    y = sorted([sub_array[1] for sub_array in points_y])\n    labels = [float(label) if label.isdigit() else 0.0 for label in df['y_val'][i]]\n    if len(labels)==0 or len(labels)==1:\n        labels = [0.0,0.0]\n    extended_y.append(extend_y_axis(y,labels))","metadata":{"execution":{"iopub.status.busy":"2023-06-05T04:56:10.511557Z","iopub.execute_input":"2023-06-05T04:56:10.514834Z","iopub.status.idle":"2023-06-05T04:56:10.526556Z","shell.execute_reply.started":"2023-06-05T04:56:10.514789Z","shell.execute_reply":"2023-06-05T04:56:10.525424Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Marker generation","metadata":{}},{"cell_type":"code","source":"import pandas as pd\nimport numpy as np\nimport cv2\nimport os\nimport re\n\nfrom PIL import Image\n\nimport albumentations as A\nfrom albumentations.pytorch.transforms import ToTensorV2\n\nimport torch\nimport torchvision\n\nfrom torchvision.models.detection.faster_rcnn import FastRCNNPredictor\nfrom torchvision.models.detection import FasterRCNN\nfrom torchvision.models.detection.rpn import AnchorGenerator\n\nfrom torch.utils.data import DataLoader, Dataset\nfrom sklearn.model_selection import train_test_split\nfrom torch.utils.data.sampler import SequentialSampler\n\nfrom matplotlib import pyplot as plt","metadata":{"execution":{"iopub.status.busy":"2023-06-05T04:56:10.531952Z","iopub.execute_input":"2023-06-05T04:56:10.535527Z","iopub.status.idle":"2023-06-05T04:56:11.707069Z","shell.execute_reply.started":"2023-06-05T04:56:10.535482Z","shell.execute_reply":"2023-06-05T04:56:11.706094Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"ids = []\nimport os\ntest_dataset_dir = CFG.image_path\nfor filename in os.listdir(test_dataset_dir):\n    if filename.endswith(\".jpg\"):\n        ids.append(filename[:-4])\ntest_df = pd.DataFrame(ids)\ntest_df.columns = ['image_id']","metadata":{"execution":{"iopub.status.busy":"2023-06-05T04:56:11.708612Z","iopub.execute_input":"2023-06-05T04:56:11.708954Z","iopub.status.idle":"2023-06-05T04:56:11.716631Z","shell.execute_reply.started":"2023-06-05T04:56:11.708921Z","shell.execute_reply":"2023-06-05T04:56:11.71522Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"class CustDataset(Dataset):\n    def __init__(self, dataframe, image_dir, transforms=None):\n        super().__init__()\n\n        self.image_ids = dataframe['image_id'].unique()\n        self.df = dataframe\n        self.image_dir = image_dir\n        self.transforms = transforms\n\n    def convert_to_rgb(self, image):\n        if len(image.shape) == 2:  # Grayscale image\n            image = np.expand_dims(image, axis=2)\n            image = np.repeat(image, 3, axis=2)\n        return image\n\n    def __getitem__(self, index: int):\n        image_id = self.image_ids[index]\n        image_path = f'{self.image_dir}/{image_id}.jpg'\n\n        image = cv2.imread(image_path, cv2.IMREAD_GRAYSCALE)  # Read image as grayscale\n        image = self.convert_to_rgb(image)  # Convert to RGB if grayscale\n        image = image.astype(np.float32) / 255.0\n\n        target = {'image_id': torch.tensor([index])}\n\n        if self.transforms:\n            sample = {'image': image}\n            sample = self.transforms(**sample)\n            image = sample['image']\n\n        return image, image_id\n\n    def __len__(self) -> int:\n        return self.image_ids.shape[0]","metadata":{"execution":{"iopub.status.busy":"2023-06-05T04:56:11.718297Z","iopub.execute_input":"2023-06-05T04:56:11.71873Z","iopub.status.idle":"2023-06-05T04:56:11.730475Z","shell.execute_reply.started":"2023-06-05T04:56:11.718698Z","shell.execute_reply":"2023-06-05T04:56:11.729469Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def get_test_transform():\n    return A.Compose([\n        A.Resize(256,256),\n        ToTensorV2(p=1.0)\n    ])","metadata":{"execution":{"iopub.status.busy":"2023-06-05T04:56:11.732126Z","iopub.execute_input":"2023-06-05T04:56:11.732507Z","iopub.status.idle":"2023-06-05T04:56:11.739438Z","shell.execute_reply.started":"2023-06-05T04:56:11.732476Z","shell.execute_reply":"2023-06-05T04:56:11.738457Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def collate_fn(batch):\n    return tuple(zip(*batch))\n\nDIR_INPUT = CFG.image_path\nDIR_TRAIN = f'{DIR_INPUT}'\ntest_dataset = CustDataset(test_df, DIR_TRAIN, get_test_transform())","metadata":{"execution":{"iopub.status.busy":"2023-06-05T04:56:11.740944Z","iopub.execute_input":"2023-06-05T04:56:11.741351Z","iopub.status.idle":"2023-06-05T04:56:11.75025Z","shell.execute_reply.started":"2023-06-05T04:56:11.741321Z","shell.execute_reply":"2023-06-05T04:56:11.749257Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"test_data_loader = DataLoader(\n    test_dataset,\n    batch_size=4,\n    shuffle=False,\n    num_workers=2,\n    collate_fn=collate_fn\n)","metadata":{"execution":{"iopub.status.busy":"2023-06-05T04:56:11.7517Z","iopub.execute_input":"2023-06-05T04:56:11.75219Z","iopub.status.idle":"2023-06-05T04:56:11.759798Z","shell.execute_reply.started":"2023-06-05T04:56:11.752159Z","shell.execute_reply":"2023-06-05T04:56:11.758912Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"model = torchvision.models.detection.fasterrcnn_mobilenet_v3_large_fpn(weights=None, weights_backbone=None)","metadata":{"execution":{"iopub.status.busy":"2023-06-05T04:56:11.76139Z","iopub.execute_input":"2023-06-05T04:56:11.761737Z","iopub.status.idle":"2023-06-05T04:56:12.030389Z","shell.execute_reply.started":"2023-06-05T04:56:11.761708Z","shell.execute_reply":"2023-06-05T04:56:12.029401Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"in_features = model.roi_heads.box_predictor.cls_score.in_features\nmodel.roi_heads.box_predictor = FastRCNNPredictor(in_features, 4)","metadata":{"execution":{"iopub.status.busy":"2023-06-05T04:56:12.038834Z","iopub.execute_input":"2023-06-05T04:56:12.039147Z","iopub.status.idle":"2023-06-05T04:56:12.044862Z","shell.execute_reply.started":"2023-06-05T04:56:12.03912Z","shell.execute_reply":"2023-06-05T04:56:12.043893Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"model.load_state_dict(torch.load('/kaggle/input/marker-model/Marker_weights.pth'))","metadata":{"execution":{"iopub.status.busy":"2023-06-05T04:56:12.046286Z","iopub.execute_input":"2023-06-05T04:56:12.047419Z","iopub.status.idle":"2023-06-05T04:56:13.046828Z","shell.execute_reply.started":"2023-06-05T04:56:12.047363Z","shell.execute_reply":"2023-06-05T04:56:13.044351Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"model.to(device)\nmodel.eval()\nresults = []\nfor images, image_ids in test_data_loader:\n    images = list(image.to(device) for image in images)\n    outputs = model(images)\n    for i, image in enumerate(images):\n        boxes = outputs[i]['boxes'].data.cpu().numpy()\n        scores = outputs[i]['scores'].data.cpu().numpy()\n        labels = outputs[i]['labels'].data.cpu().numpy()\n        image_id = image_ids[i]\n        result = {\n            'image_id': image_id,\n            'boxes': boxes,\n            'labels': labels,\n            'scores': scores\n        }\n        results.append(result)\n    \n    del images, outputs ","metadata":{"execution":{"iopub.status.busy":"2023-06-05T04:56:13.049827Z","iopub.execute_input":"2023-06-05T04:56:13.051056Z","iopub.status.idle":"2023-06-05T04:56:13.60644Z","shell.execute_reply.started":"2023-06-05T04:56:13.050986Z","shell.execute_reply":"2023-06-05T04:56:13.605107Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df3 = pd.DataFrame(results)","metadata":{"execution":{"iopub.status.busy":"2023-06-05T04:56:13.608845Z","iopub.execute_input":"2023-06-05T04:56:13.609298Z","iopub.status.idle":"2023-06-05T04:56:13.617039Z","shell.execute_reply.started":"2023-06-05T04:56:13.60925Z","shell.execute_reply":"2023-06-05T04:56:13.615984Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import matplotlib.pyplot as plt\ni = 1\nprint(df['x_val'][i])\nprint(df['y_val'][i])\npoints_x = df2['x_points'][i]\npoints_y = df2['y_points'][i]\nboxes = df3['boxes'][i]\nboxes = boxes[np.logical_and(df3['labels'][i] == 3, df3['scores'][i] >= 0.5)].astype(np.int32)\nimg_path = CFG.image_path+'/'+df2['image_id'][i]+'.jpg'\nimage = cv2.imread(img_path)\nimg = cv2.resize(image, (256, 256))\nfig, ax = plt.subplots(1, 1, figsize=(16, 8))\nfor point in points_x:\n    x = point[0]\n    y = point[1]\n    ax.plot(x, y, 'ro')\n\nfor point in points_y:\n    x = point[0]\n    y = point[1]\n    ax.plot(x, y, 'ro')\nfor box in boxes:\n    cv2.rectangle(img,\n                  (box[0], box[1]),\n                  (box[2], box[3]),\n                  (220,0, 0), 1)\nax.axis('off')\nax.imshow(img)","metadata":{"execution":{"iopub.status.busy":"2023-06-05T04:56:13.618871Z","iopub.execute_input":"2023-06-05T04:56:13.620098Z","iopub.status.idle":"2023-06-05T04:56:13.941271Z","shell.execute_reply.started":"2023-06-05T04:56:13.620065Z","shell.execute_reply":"2023-06-05T04:56:13.940334Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"class PredBarPlot():\n    def __init__(self,marker,scores,labels,y_points,y_labels):\n        self.marker = marker\n        self.scores = scores\n        self.labels = labels\n        self.y_points = y_points\n        self.detection_threshold = 0.5\n        self.y_labels = y_labels\n    \n    def calculate_center(self,box):\n        center_x = (box[0] + box[2]) / 2\n        center_y = (box[1] + box[3]) / 2\n        return center_x, center_y\n    \n    def calculate_iou(self,box1, box2):\n        x1 = max(box1[0], box2[0])\n        y1 = max(box1[1], box2[1])\n        x2 = min(box1[2], box2[2])\n        y2 = min(box1[3], box2[3])\n        intersection_area = max(0, x2 - x1 + 1) * max(0, y2 - y1 + 1)\n        box1_area = (box1[2] - box1[0] + 1) * (box1[3] - box1[1] + 1)\n        box2_area = (box2[2] - box2[0] + 1) * (box2[3] - box2[1] + 1)\n        iou = intersection_area / float(box1_area + box2_area - intersection_area)\n        return iou\n    \n    def remove_high_iou_boxes(self,boxes, threshold):\n        redundant_indices = []\n        for i in range(len(boxes)):\n            for j in range(i + 1, len(boxes)):\n                iou = self.calculate_iou(boxes[i], boxes[j])\n                if iou > threshold:\n                    redundant_indices.append(j)\n        filtered_boxes = [box for i, box in enumerate(boxes) if i not in redundant_indices]\n        return filtered_boxes\n    \n    def find_element_above(self,number,lst):\n        lst.sort()\n        for element in lst:\n            if element > number:\n                return element\n        return None  \n    \n    def generate_output(self):\n        marker = self.marker[np.logical_and(self.labels == 3, scores >= self.detection_threshold)]\n        marker = self.remove_high_iou_boxes(marker,0.0)\n        marker_p = []\n        for i in range(len(marker)):\n            x,y = self.calculate_center(marker[i])\n            marker_p.append([x,y])\n        marker_p = sorted(marker_p, key=lambda x: x[0])\n        result = []\n        for i in range(len(marker_p)):\n            el = self.find_element_above(marker_p[i][1],self.y_points)\n            if el==None:\n                el = self.y_points[0]\n            index = self.y_points.index(el)\n            diff = self.y_points[index] - marker_p[i][1] \n            least_count = (self.y_labels[index]-self.y_labels[index-1])/(self.y_points[index-1]-self.y_points[index])\n            res = self.y_labels[index]+diff*least_count\n            result.append(res)\n        return result","metadata":{"execution":{"iopub.status.busy":"2023-06-05T04:56:13.942319Z","iopub.execute_input":"2023-06-05T04:56:13.942695Z","iopub.status.idle":"2023-06-05T04:56:13.961436Z","shell.execute_reply.started":"2023-06-05T04:56:13.942661Z","shell.execute_reply":"2023-06-05T04:56:13.960555Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"class PredLinePlot():\n    def __init__(self,marker,scores,labels,x_points,y_points,y_labels):\n        self.marker = marker\n        self.scores = scores\n        self.labels = labels\n        self.x_points = x_points\n        self.y_points = y_points\n        self.detection_threshold = 0.5\n        self.y_labels = y_labels\n        \n    def calculate_center(self,box):\n        center_x = (box[0] + box[2]) / 2\n        center_y = (box[1] + box[3]) / 2\n        return center_x, center_y\n    \n    def closest_point(self,number, point_list):\n        closest = None\n        min_difference = float('inf')\n        for point in point_list:\n            difference = abs(number - point)\n            if difference < min_difference:\n                min_difference = difference\n                closest = point\n        return closest\n    \n    def find_element_above(self,number,lst):\n        lst.sort()\n        for element in lst:\n            if element > number:\n                return element\n        return None  \n    \n    def generate_output(self):\n        marker = self.marker[np.logical_and(self.labels == 3, self.scores >= 0.0)]\n        marker_points_x = []\n        marker_points_y = []\n        for i in range(len(marker)):\n            x,y = self.calculate_center(marker[i])\n            marker_points_x.append(x)\n            marker_points_y.append(y)\n        data = []\n        for i in range(len(self.x_points)):\n            el = self.closest_point(self.x_points[i],marker_points_x)\n            index = marker_points_x.index(el)\n            data.append([marker_points_x[index],marker_points_y[index]])\n        data = sorted(data, key=lambda x: x[0])\n        result = []\n        for i in range(len(data)):\n            el = self.find_element_above(data[i][1],self.y_points)\n            if el == None:\n                el = y_points[0]\n            index = self.y_points.index(el)\n            diff = self.y_points[index] - data[i][1] \n            least_count = (self.y_labels[index]-self.y_labels[index-1])/(self.y_points[index-1]-self.y_points[index])\n            res = self.y_labels[index]+diff*least_count\n            result.append(res)\n            \n        return result","metadata":{"execution":{"iopub.status.busy":"2023-06-05T04:56:13.964575Z","iopub.execute_input":"2023-06-05T04:56:13.9651Z","iopub.status.idle":"2023-06-05T04:56:13.981215Z","shell.execute_reply.started":"2023-06-05T04:56:13.965074Z","shell.execute_reply":"2023-06-05T04:56:13.980247Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"class PredScatterPlot():\n    def __init__(self,marker,scores,labels,y_points,y_labels):\n        self.marker = marker\n        self.scores = scores\n        self.labels = labels\n        self.y_points = y_points\n        self.detection_threshold = 0.5\n        self.y_labels = y_labels\n    \n    def calculate_center(self,box):\n        center_x = (box[0] + box[2]) / 2\n        center_y = (box[1] + box[3]) / 2\n        return center_x, center_y\n    \n    def find_element_above(self,number,lst):\n        lst.sort()\n        for element in lst:\n            if element > number:\n                return element\n        return None  \n    \n    def generate_output(self):\n        marker = self.marker[np.logical_and(self.labels == 3, scores >= self.detection_threshold)]\n        marker_p = []\n        for i in range(len(marker)):\n            x,y = self.calculate_center(marker[i])\n            marker_p.append([x,y])\n        marker_p = sorted(marker_p, key=lambda x: x[0])\n        result = []\n        for i in range(len(marker_p)):\n            el = self.find_element_above(marker_p[i][1],self.y_points)\n            if(el==None):\n                el = self.y_points[0]\n            index = self.y_points.index(el)\n            diff = self.y_points[index] - marker_p[i][1] \n            least_count = (self.y_labels[index]-self.y_labels[index-1])/(self.y_points[index-1]-self.y_points[index])\n            res = self.y_labels[index]+diff*least_count\n            result.append(res)\n        return result","metadata":{"execution":{"iopub.status.busy":"2023-06-05T04:56:13.983789Z","iopub.execute_input":"2023-06-05T04:56:13.984069Z","iopub.status.idle":"2023-06-05T04:56:13.998998Z","shell.execute_reply.started":"2023-06-05T04:56:13.984041Z","shell.execute_reply":"2023-06-05T04:56:13.99806Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"class PredDotPlot():\n    def __init__(self,marker,scores,labels,x_points,y_points,y_labels):\n        self.marker = marker\n        self.scores = scores\n        self.labels = labels\n        self.x_points = x_points\n        self.y_points = y_points\n        self.detection_threshold = 0.5\n        self.y_labels = y_labels\n    \n    def calculate_center(self,box):\n        center_x = (box[0] + box[2]) / 2\n        center_y = (box[1] + box[3]) / 2\n        return center_x, center_y\n    \n    def count_points_with_same_x(self,target_point, points, tolerance):\n        count = 0\n        for point in points:\n            if abs(point[0] - target_point[0]) <= tolerance:\n                count += 1\n        return count\n    \n    def calculate_iou(self,box1, box2):\n        x1 = max(box1[0], box2[0])\n        y1 = max(box1[1], box2[1])\n        x2 = min(box1[2], box2[2])\n        y2 = min(box1[3], box2[3])\n        intersection_area = max(0, x2 - x1 + 1) * max(0, y2 - y1 + 1)\n        box1_area = (box1[2] - box1[0] + 1) * (box1[3] - box1[1] + 1)\n        box2_area = (box2[2] - box2[0] + 1) * (box2[3] - box2[1] + 1)\n        iou = intersection_area / float(box1_area + box2_area - intersection_area)\n        return iou\n    \n    def remove_high_iou_boxes(self,boxes, threshold):\n        redundant_indices = []\n        for i in range(len(boxes)):\n            for j in range(i + 1, len(boxes)):\n                iou = self.calculate_iou(boxes[i], boxes[j])\n                if iou > threshold:\n                    redundant_indices.append(j)\n        filtered_boxes = [box for i, box in enumerate(boxes) if i not in redundant_indices]\n        return filtered_boxes\n    \n    def generate_output(self):\n        marker = self.marker[np.logical_and(self.labels == 3, self.scores >= self.detection_threshold)]\n        marker = self.remove_high_iou_boxes(marker,0.0)\n        marker_points = []\n        for i in range(len(marker)):\n            x,y = self.calculate_center(marker[i])\n            marker_points.append([x,y])\n        scale = abs(self.y_labels[0]-self.y_labels[1])\n        y_min = 0\n        res = []\n        for i in range(len(self.x_points)):\n            count = self.count_points_with_same_x(self.x_points[i],marker_points,10)\n            res.append(y_min+scale*count)\n        res = [int(element) for element in res]\n        return res","metadata":{"execution":{"iopub.status.busy":"2023-06-05T04:56:14.000658Z","iopub.execute_input":"2023-06-05T04:56:14.001207Z","iopub.status.idle":"2023-06-05T04:56:14.018532Z","shell.execute_reply.started":"2023-06-05T04:56:14.001175Z","shell.execute_reply":"2023-06-05T04:56:14.017463Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"chart_types, x_preds, y_preds = [], [], []\nfor i in range(len(df)):\n    result = []\n    if df['chart_types'][i] == 'line':\n        '''\n        result = [0.0,0.0]\n        boxes = df3['boxes'][i]\n        scores = df3['scores'][i]\n        labels = df3['labels'][i]\n        y_points = [sub_array[0] for sub_array in extended_y[i]]\n        y_labels = [sub_array[1] for sub_array in extended_y[i]]\n        x_points = df2['x_points'][i]\n        x_points = [sub_array[0] for sub_array in x_points]\n        x_points = sorted(x_points)\n        pred_line_plot = PredLinePlot(boxes,scores,labels,x_points,y_points,y_labels)\n        result = pred_line_plot.generate_output()'''\n        result = [0.0,0.0]\n    \n    elif df['chart_types'][i] == 'vertical_bar':\n        boxes = df3['boxes'][i]\n        scores = df3['scores'][i]\n        labels = df3['labels'][i]\n        y_points = [sub_array[0] for sub_array in extended_y[i]]\n        y_labels = [sub_array[1] for sub_array in extended_y[i]]\n        pred_bar_plot = PredBarPlot(boxes,scores,labels,y_points,y_labels)\n        result = pred_bar_plot.generate_output()\n    \n    elif df['chart_types'][i] == 'dot':\n        boxes = df3['boxes'][i]\n        scores = df3['scores'][i]\n        labels = df3['labels'][i]\n        y_points = [sub_array[0] for sub_array in extended_y[i]]\n        y_labels = [sub_array[1] for sub_array in extended_y[i]]\n        x_points = df2['x_points'][i]\n        pred_dot_plot = PredDotPlot(boxes,scores,labels,x_points,y_points,y_labels)\n        result = pred_dot_plot.generate_output()\n    \n    elif df['chart_types'][i] == 'scatter':\n        result = [0.0,0.0]\n        boxes = df3['boxes'][i]\n        scores = df3['scores'][i]\n        labels = df3['labels'][i]\n        y_points = [sub_array[0] for sub_array in extended_y[i]]\n        y_labels = [sub_array[1] for sub_array in extended_y[i]]\n        pred_scatter_plot = PredScatterPlot(boxes,scores,labels,y_points,y_labels)\n        result = pred_scatter_plot.generate_output()\n        \n    chart_types.append(df['chart_types'][i])\n    x_labels = df['x_val'][i]\n    '''\n    boxes = df2[df2['image_id']==df['image_id'][i]]['boxes'][i]\n    scores = df2[df2['image_id']==df['image_id'][i]]['scores'][i]\n    labels = df2[df2['image_id']==df['image_id'][i]]['labels'][i]\n    x_boxes = boxes[np.logical_and(labels == 1,scores >= 0.5)]\n    l = len(x_boxes)\n    x_labels = x_labels[:l]'''\n    x_str = \";\".join(list(map(str, x_labels)))\n    y_str = \";\".join(list(map(str, result)))\n    x_preds.append(x_str)\n    y_preds.append(y_str)","metadata":{"execution":{"iopub.status.busy":"2023-06-05T04:56:14.020081Z","iopub.execute_input":"2023-06-05T04:56:14.020455Z","iopub.status.idle":"2023-06-05T04:56:14.040329Z","shell.execute_reply.started":"2023-06-05T04:56:14.020418Z","shell.execute_reply":"2023-06-05T04:56:14.039357Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"sub_df = pd.DataFrame(\n    data={\n        \"id\": [f\"{id_}_x\" for id_ in ids] + [f\"{id_}_y\" for id_ in ids],\n        \"data_series\": x_preds + y_preds,\n        \"chart_type\": chart_types * 2,\n    }\n)","metadata":{"execution":{"iopub.status.busy":"2023-06-05T04:56:14.043314Z","iopub.execute_input":"2023-06-05T04:56:14.043969Z","iopub.status.idle":"2023-06-05T04:56:14.053074Z","shell.execute_reply.started":"2023-06-05T04:56:14.043939Z","shell.execute_reply":"2023-06-05T04:56:14.051987Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"for i in range(len(sub_df)):\n    sub_df['data_series'][i] = [0.0 if val == 'nan' else val for val in sub_df['data_series'][i].split(';')]\n    sub_df['data_series'][i] = \";\".join(list(map(str, sub_df['data_series'][i])))","metadata":{"execution":{"iopub.status.busy":"2023-06-05T04:56:14.055239Z","iopub.execute_input":"2023-06-05T04:56:14.05582Z","iopub.status.idle":"2023-06-05T04:56:14.065878Z","shell.execute_reply.started":"2023-06-05T04:56:14.055788Z","shell.execute_reply":"2023-06-05T04:56:14.064843Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"sub_df['data_series'] = sub_df['data_series'].replace('', 0.0)","metadata":{"execution":{"iopub.status.busy":"2023-06-05T04:56:14.067529Z","iopub.execute_input":"2023-06-05T04:56:14.067932Z","iopub.status.idle":"2023-06-05T04:56:14.07546Z","shell.execute_reply.started":"2023-06-05T04:56:14.067898Z","shell.execute_reply":"2023-06-05T04:56:14.074269Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"sub_df.to_csv('submission.csv', index=False)","metadata":{"execution":{"iopub.status.busy":"2023-06-05T04:56:14.077037Z","iopub.execute_input":"2023-06-05T04:56:14.07739Z","iopub.status.idle":"2023-06-05T04:56:14.085775Z","shell.execute_reply.started":"2023-06-05T04:56:14.077359Z","shell.execute_reply":"2023-06-05T04:56:14.084703Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}